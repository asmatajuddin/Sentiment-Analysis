{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NLTK Sentiment Analysis Tutorial for Beginners\n",
        "\n",
        "Artificial Intelligence (AI)\n",
        "\n",
        "Python\n"
      ],
      "metadata": {
        "id": "VMWlEWnyPR6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "id": "T6IeEzfkPVS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "GOeCitQ8PdPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "# download nltk corpus (first time only)\n",
        "import nltk\n",
        "\n",
        "nltk.download('all')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load the amazon review dataset\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/amazon.csv')\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "APkunBgDPfRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create preprocess_text function\n",
        "def preprocess_text(text):\n",
        "\n",
        "    # Tokenize the text\n",
        "\n",
        "    tokens = word_tokenize(text.lower())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Remove stop words\n",
        "\n",
        "    filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Lemmatize the tokens\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Join the tokens back into a string\n",
        "\n",
        "    processed_text = ' '.join(lemmatized_tokens)\n",
        "\n",
        "    return processed_text\n",
        "\n",
        "# apply the function df\n",
        "\n",
        "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
        "df"
      ],
      "metadata": {
        "id": "4EpdIPVoPh1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize NLTK sentiment analyzer\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "\n",
        "# create get_sentiment function\n",
        "\n",
        "def get_sentiment(text):\n",
        "\n",
        "    scores = analyzer.polarity_scores(text)\n",
        "\n",
        "    sentiment = 1 if scores['pos'] > 0 else 0\n",
        "\n",
        "    return sentiment\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# apply get_sentiment function\n",
        "\n",
        "df['sentiment'] = df['reviewText'].apply(get_sentiment)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "dZ3QFdNZPk2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(confusion_matrix(df['Positive'], df['sentiment']))"
      ],
      "metadata": {
        "id": "z1ZcMJ7bPoz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(df['Positive'], df['sentiment']))"
      ],
      "metadata": {
        "id": "t42-j7H3Ppa3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}